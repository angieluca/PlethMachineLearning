{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thesis Project - Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook tests out different ML models and check the scores. \n",
    "\n",
    "The training dataset contains a total of ? samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/SuperPawn/Documents/GitHub/PlethMachineLearning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 19) (265,)\n"
     ]
    }
   ],
   "source": [
    "# Loading Data\n",
    "data_train = np.load('data_train.npy', allow_pickle=True)\n",
    "labels_train = np.load('labels_train.npy', allow_pickle=True)\n",
    "\n",
    "print(data_train.shape, labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "napoli_test = np.load('napoli_data.npy', allow_pickle=True)\n",
    "labels_test = np.load('napoli_labels.npy', allow_pickle=True)\n",
    "\n",
    "#print(da_train.shape, labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels Encoding\n",
    "\n",
    "labels_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Counting number samples per class\n",
    "vals, counts = np.unique(labels_train, return_counts=True)\n",
    "\n",
    "plt.bar(vals, counts)\n",
    "plt.xticks(range(7),range(7))\n",
    "plt.xlabel('Classes',size=20)\n",
    "plt.ylabel('# Samples per Class', size=20)\n",
    "plt.title('Training Data (Total = '+str(data_train.shape[0])+' samples)',size=15);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from skimage.transform import resize\n",
    "from sklearn.svm import SVC\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 19)\n",
      "(212,)\n",
      "(53, 19)\n",
      "(53,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, t_train, t_test = train_test_split(data_train, labels_train, \n",
    "                                                   test_size=0.2,\n",
    "                                                   stratify=labels_train,\n",
    "                                                   random_state=0)\n",
    "print(X_train.shape)\n",
    "print(t_train.shape)\n",
    "print(X_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 19)\n",
      "(212,)\n",
      "(53, 19)\n",
      "(53,)\n"
     ]
    }
   ],
   "source": [
    "X_napoli_train, X_napoli_test, t_napoli_train, t_napoli_test = train_test_split(napoli_test, labels_test, \n",
    "                                                   test_size=0.5,\n",
    "                                                   random_state=0)\n",
    "print(X_train.shape)\n",
    "print(t_train.shape)\n",
    "print(X_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) LDA + LOGISTIC REGRESSION (Model No.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('SCALER', StandardScaler()),\n",
       "                ('LDA', LinearDiscriminantAnalysis(n_components=3)),\n",
       "                ('LOGRES', LogisticRegression())])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1 = Pipeline([('SCALER', StandardScaler()),\n",
    "                 ('LDA', LDA(n_components=3)),\n",
    "                 ('LOGRES', LogisticRegression())])\n",
    "mod1.fit(X_train, t_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################   RUN GRIDSEARCHCV ON ALL    ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_test1 = mod1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test1 = mod1.predict(X_napoli_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [53, 39]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-05ec98d7b6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LR\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'F1_score:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion matrix:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [53, 39]"
     ]
    }
   ],
   "source": [
    "print('LR\\n')\n",
    "print('Accuracy:\\n',accuracy_score(t_test, pred_test1))\n",
    "print ('F1_score:\\n',f1_score(t_test, pred_test1, average=None))\n",
    "print('Confusion matrix:\\n',confusion_matrix(t_test, pred_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "\n",
      "Accuracy:\n",
      " 0.8461538461538461\n",
      "F1_score:\n",
      " [0.7        1.         1.         0.57142857]\n",
      "Confusion matrix:\n",
      " [[ 7  0  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  0 13  0]\n",
      " [ 6  0  0  4]]\n"
     ]
    }
   ],
   "source": [
    "print('LR\\n')\n",
    "print('Accuracy:\\n',accuracy_score(t_napoli_test, pred_test1))\n",
    "print ('F1_score:\\n',f1_score(t_napoli_test, pred_test1, average=None))\n",
    "print('Confusion matrix:\\n',confusion_matrix(t_napoli_test, pred_test1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) PCA + LOGISTIC REGRESSION (Model No. 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18]),)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 0 with size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-2955a863ed7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of principal components'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'% Variance explained'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 20 is out of bounds for axis 0 with size 19"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N, D = np.shape(X_train)\n",
    "pca = PCA(n_components=min(N,D))\n",
    "pca.fit(X_train)\n",
    "\n",
    "plt.step(range(1,min(N,D)+1),np.cumsum(pca.explained_variance_ratio_)*100)\n",
    "\n",
    "print(np.where(np.cumsum(pca.explained_variance_ratio_)>=0.9))\n",
    "print(np.cumsum(pca.explained_variance_ratio_)[20])\n",
    "plt.xlabel('Number of principal components');\n",
    "plt.ylabel('% Variance explained');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2 = Pipeline([('SCALER', StandardScaler()),\n",
    "                 ('PCA', PCA(n_components=26)),\n",
    "                 ('LOGREG', LogisticRegression(random_state=0, tol=0.01))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=26 must be between 0 and min(n_samples, n_features)=19 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-a2a3cc8e8a9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \"\"\"\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    437\u001b[0m                                  \"if n_samples >= n_features\")\n\u001b[1;32m    438\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             raise ValueError(\"n_components=%r must be between 0 and \"\n\u001b[0m\u001b[1;32m    440\u001b[0m                              \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                              \u001b[0;34m\"svd_solver='full'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=26 must be between 0 and min(n_samples, n_features)=19 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "mod2.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'mean_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-2ff6760d1959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'With PCA:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Accuracy Score = '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion matrix:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'mean_'"
     ]
    }
   ],
   "source": [
    "pred_test2 = mod2.predict(X_test)\n",
    "\n",
    "print('With PCA:')\n",
    "print('Test Accuracy Score = ',accuracy_score(t_test, pred_test2))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(t_test, pred_test2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'mean_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-03e184ca0510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_napoli_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_napoli_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'F1_score:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_napoli_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion matrix:\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_napoli_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'mean_'"
     ]
    }
   ],
   "source": [
    "pred_test2 = mod2.predict(X_napoli_test)\n",
    "\n",
    "print('Accuracy:\\n',accuracy_score(t_napoli_test, pred_test2))\n",
    "print ('F1_score:\\n',f1_score(t_napoli_test, pred_test2, average=None))\n",
    "print('Confusion matrix:\\n',confusion_matrix(t_napoli_test, pred_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Random Forest (Model No. 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npred_test3 = rf_classifier.predict(X_test)\\n\\nprint('With Random Forest:')\\nprint('Test Accuracy Score = ',accuracy_score(t_test, pred_test3))\\nprint('Confusion matrix:')\\nprint(confusion_matrix(t_test, pred_test3))\\n\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pred_test3 = rf_classifier.predict(X_test)\n",
    "\n",
    "print('With Random Forest:')\n",
    "print('Test Accuracy Score = ',accuracy_score(t_test, pred_test3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(t_test, pred_test3))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Random Forest:\n",
      "Test Accuracy Score =  1.0\n",
      "Confusion matrix:\n",
      "[[ 7  0  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  0 13  0]\n",
      " [ 0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "pred_test3 = rf_classifier.predict(X_napoli_test)\n",
    "\n",
    "print('With Random Forest:')\n",
    "print('Test Accuracy Score = ',accuracy_score(t_napoli_test, pred_test3))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(t_napoli_test, pred_test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) XGBoost (Model No.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax', num_class=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:13:23] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SuperPawn/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_class=5, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier on the training data\n",
    "xgb_classifier.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With XGBoost:\n",
      "Test Accuracy Score =  0.9710144927536232\n",
      "Confusion matrix:\n",
      "[[19  0  0  1]\n",
      " [ 0 14  0  1]\n",
      " [ 0  0 20  0]\n",
      " [ 0  0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "pred_test4 = xgb_classifier.predict(X_test)\n",
    "\n",
    "print('With XGBoost:')\n",
    "print('Test Accuracy Score = ',accuracy_score(t_test, pred_test4))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(t_test, pred_test4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) CNN (Model No. 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-3d1e6d42ad48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5933, 270000), (5933,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full = np.load('data_train.npy').T\n",
    "t_train_full = np.load('labels_train_corrected.npy')\n",
    "\n",
    "X_train_full.shape, t_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5043, 270000), (5043,), (4034, 270000), (4034,), (1009, 270000), (1009,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training and Test sets\n",
    "X_training, X_test, t_training, t_test = train_test_split(X_train_full, \n",
    "                                                  t_train_full, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=t_train_full,\n",
    "                                                  test_size=0.15)\n",
    "# Train and validation sets\n",
    "X_train, X_val, t_train, t_val = train_test_split(X_training, \n",
    "                                                  t_training, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=t_training,\n",
    "                                                  test_size=0.2)\n",
    "\n",
    "X_training.shape, t_training.shape, X_train.shape, t_train.shape, X_val.shape, t_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_full, t_train_full\n",
    "# free up space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_training = X_training.reshape(X_training.shape[0], 300, 300, 3)/255.0\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 300, 300, 3)/255.0\n",
    "\n",
    "X_val = X_val.reshape(X_val.shape[0], 300, 300, 3)/255.0\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 300, 300, 3)/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation='relu', padding='same', input_shape=[300,300,3]), \n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    keras.layers.Conv2D(128, 3, activation='relu', padding='same'), \n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.MaxPooling2D(2), \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer=keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "127/127 [==============================] - 329s 3s/step - loss: 7.6946 - accuracy: 0.1004 - val_loss: 2.3032 - val_accuracy: 0.0991\n",
      "Epoch 2/2\n",
      "127/127 [==============================] - 324s 3s/step - loss: 2.3043 - accuracy: 0.0910 - val_loss: 2.3029 - val_accuracy: 0.1011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c374bc5970>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, t_train, epochs=2, batch_size=32,\n",
    "          validation_data=(X_val, t_val),\n",
    "         callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 13s 477ms/step - loss: 2.3029 - accuracy: 0.1011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3029372692108154, 0.10112359374761581]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Pre-trained CNN Model Using ResNet without Regularization (Model No. 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5933, 270000), (5933,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full = np.load('data_train.npy').T\n",
    "t_train_full = np.load('labels_train_corrected.npy')\n",
    "\n",
    "X_train_full.shape, t_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5043, 270000), (5043,), (4034, 270000), (4034,), (1009, 270000), (1009,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training and Test sets\n",
    "X_training, X_test, t_training, t_test = train_test_split(X_train_full, \n",
    "                                                  t_train_full, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=t_train_full,\n",
    "                                                  test_size=0.15)\n",
    "# Train and validation sets\n",
    "X_train, X_val, t_train, t_val = train_test_split(X_training, \n",
    "                                                  t_training, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=t_training,\n",
    "                                                  test_size=0.2)\n",
    "\n",
    "X_training.shape, t_training.shape, X_train.shape, t_train.shape, X_val.shape, t_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training_reshaped = X_training.reshape(-1, 300, 300, 3)\n",
    "X_test_reshaped = X_test.reshape(-1, 300, 300, 3)\n",
    "\n",
    "# Reshape the input data to match the model's expected input shape\n",
    "X_train_reshaped = X_train.reshape(-1, 300, 300, 3)\n",
    "X_val_reshaped = X_val.reshape(-1, 300, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.resnet50.ResNet50(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Linear(numFeatures, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256, len(trainDS.classes))\n",
    "        # nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 150\n",
    "\n",
    "# .Input() instantiates a Keras tensor\n",
    "inputs = keras.Input(shape=(300, 300, 3))\n",
    "# Input layer\n",
    "\n",
    "inputs_resized = tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE)(inputs)\n",
    "# resizing input to match pretrained model\n",
    "\n",
    "x = base_model(inputs_resized, training=False)\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 300, 300, 3]),\n",
       " TensorShape([None, 150, 150, 3]),\n",
       " TensorShape([None, 5, 5, 2048]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, inputs_resized.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 51200])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Flattening\n",
    "\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x_flatten = keras.layers.Flatten()(x)\n",
    "\n",
    "x_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Dense classifier with 10 units and softmax activation function\n",
    "outputs = keras.layers.Dense(10, activation='softmax')(x_flatten)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.functional.Functional"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 300, 300, 3]),\n",
       " TensorShape([None, 150, 150, 3]),\n",
       " TensorShape([None, 5, 5, 2048]),\n",
       " TensorShape([None, 10]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, inputs_resized.shape, x.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "127/127 [==============================] - 112s 842ms/step - loss: 643.4494 - accuracy: 0.3265 - val_loss: 1053.8110 - val_accuracy: 0.2319\n",
      "Epoch 2/5\n",
      "127/127 [==============================] - 111s 877ms/step - loss: 403.5866 - accuracy: 0.4958 - val_loss: 1754.6864 - val_accuracy: 0.1903\n",
      "Epoch 3/5\n",
      "127/127 [==============================] - 107s 841ms/step - loss: 329.6902 - accuracy: 0.5885 - val_loss: 927.3879 - val_accuracy: 0.2963\n",
      "Epoch 4/5\n",
      "127/127 [==============================] - 106s 839ms/step - loss: 236.7023 - accuracy: 0.6490 - val_loss: 561.5453 - val_accuracy: 0.4281\n",
      "Epoch 5/5\n",
      "127/127 [==============================] - 106s 839ms/step - loss: 193.1102 - accuracy: 0.7035 - val_loss: 3759.5913 - val_accuracy: 0.1308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c49bc9f850>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Nadam(learning_rate=0.01, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_reshaped,t_train, epochs=5, batch_size=32,\n",
    "          validation_data=(X_val_reshaped, t_val),\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])\n",
    "\n",
    "# Again, in practice, you would run for a lot more epochs. \n",
    "# As well as perform the necessary hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 20s 707ms/step - loss: 3681.6174 - accuracy: 0.1337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3681.617431640625, 0.13370786607265472]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_reshaped, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 21s 713ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(890,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label predictions\n",
    "y_test = np.argmax(model.predict(X_test_reshaped),axis=1)\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Nike       1.00      0.02      0.04        90\n",
      "       Adidas       0.00      0.00      0.00        88\n",
      "         Ford       0.86      0.07      0.13        88\n",
      "        Honda       0.67      0.09      0.16        88\n",
      "General Mills       0.00      0.00      0.00        90\n",
      "     Unilever       1.00      0.01      0.02        91\n",
      "   McDonald's       0.10      1.00      0.19        88\n",
      "          KFC       1.00      0.02      0.04        88\n",
      "       Gators       0.86      0.14      0.24        88\n",
      "           3M       0.00      0.00      0.00        91\n",
      "\n",
      "     accuracy                           0.13       890\n",
      "    macro avg       0.55      0.14      0.08       890\n",
      " weighted avg       0.55      0.13      0.08       890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renii\\.conda\\envs\\EEE4773\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\renii\\.conda\\envs\\EEE4773\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\renii\\.conda\\envs\\EEE4773\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(t_test, y_test, target_names=labels_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Pre-trained CNN Model Using ResNet with Regularization (Model No.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.keras.utils.set_random_seed(\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial on Data Augmentation:\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, label):\n",
    "  fig = plt.figure()\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.title(label)\n",
    "  plt.imshow(image/255.0)\n",
    "    \n",
    "    \n",
    "\n",
    "def visualize_both(original, augmented):\n",
    "  fig = plt.figure()\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.title('Original image')\n",
    "  plt.imshow(original)\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.title('Augmented image')\n",
    "  plt.imshow(augmented/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape(-1, 300, 300, 3)\n",
    "X_val_reshaped = X_train.reshape(-1, 300, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  keras.layers.RandomFlip(\"horizontal\"),\n",
    "  keras.layers.RandomRotation(0.2),\n",
    "  keras.layers.RandomBrightness(0.3),\n",
    "  keras.layers.RandomContrast(0.4),\n",
    "  #keras.layers.RandomCrop(height=0.5,width=0.5,seed=0),\n",
    "  keras.layers.RandomZoom(height_factor=0.5,width_factor=0.5,seed=0),\n",
    "  #keras.layers.RandomWidth(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20170,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sample = X_train_reshaped\n",
    "t_train_sample = t_train\n",
    "\n",
    "#X_train_sample = X_train_reshaped[0,:,:,:]\n",
    "#t_train_sample = t_train[0]\n",
    "\n",
    "t_train_append = np.append(t_train_sample,t_train_sample)\n",
    "t_train_append = np.append(t_train_append,t_train_sample)\n",
    "t_train_append = np.append(t_train_append,t_train_sample)\n",
    "t_train_append = np.append(t_train_append,t_train_sample)\n",
    "\n",
    "t_train_append.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(t_train_append.shape[0]):\n",
    "#    print(t_train_append[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_augmented_dataset(dataset):\n",
    "    augmented_dataset =data_augmentation(dataset)\n",
    "    augmented_dataset_numpy = augmented_dataset.numpy()\n",
    "    return augmented_dataset_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "augmented_dataset1 = return_augmented_dataset(X_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x0000018D6240D0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x0000018D61921E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "augmented_dataset2 = return_augmented_dataset(X_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "augmented_dataset3 = return_augmented_dataset(X_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2 cause Input \"contrast_factor\" of op 'AdjustContrastv2' expected to be loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "augmented_dataset4 = return_augmented_dataset(X_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataset = np.append(X_train_reshaped,augmented_dataset1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataset = np.append(augmented_dataset,augmented_dataset2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataset = np.append(augmented_dataset,augmented_dataset3, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataset = np.append(augmented_dataset,augmented_dataset4, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20170, 300, 300, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing / Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5933, 270000), (5933,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full = np.load('data_train.npy').T\n",
    "t_train_full = np.load('labels_train_corrected.npy')\n",
    "X_train_augmented = np.load('X_train_augmented.npy')\n",
    "t_train_augmented = np.load('t_train_augmented.npy')\n",
    "\n",
    "X_train_full.shape, t_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5043, 270000), (5043,), (4034, 270000), (4034,), (1009, 270000), (1009,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Training and Test sets\n",
    "X_training, X_test, t_training, t_test = train_test_split(X_train_full, \n",
    "                                                  t_train_full, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=t_train_full,\n",
    "                                                  test_size=0.15)\n",
    "# Train and validation sets\n",
    "X_train, X_val, t_train, t_val = train_test_split(X_training, \n",
    "                                                  t_training, \n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=t_training,\n",
    "                                                  test_size=0.2)\n",
    "\n",
    "X_training.shape, t_training.shape, X_train.shape, t_train.shape, X_val.shape, t_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_training = X_training.reshape(X_training.shape[0], 300, 300, 3)/255.0\n",
    "\n",
    "#X_train = X_train.reshape(X_train.shape[0], 300, 300, 3)/255.0\n",
    "\n",
    "#X_val = X_val.reshape(X_val.shape[0], 300, 300, 3)/255.0\n",
    "\n",
    "#X_test = X_test.reshape(X_test.shape[0], 300, 300, 3)/255.0\n",
    "\n",
    "X_training_reshaped = X_training.reshape(-1, 300, 300, 3)\n",
    "X_test_reshaped = X_test.reshape(-1, 300, 300, 3)\n",
    "\n",
    "# Reshape the input data to match the model's expected input shape\n",
    "X_train_reshaped = X_train.reshape(-1, 300, 300, 3)\n",
    "X_val_reshaped = X_val.reshape(-1, 300, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.resnet50.ResNet50(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 5, 5, 2048)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq = tf.keras.Sequential()\n",
    "model_seq.add(keras.layers.Dropout(0.25))\n",
    "model_seq.add(base_model)\n",
    "\n",
    "#model_seq.add(keras.layers.Flatten())\n",
    "model_seq.add(keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "model_seq.add(keras.layers.Dropout(0.50))\n",
    "model_seq.add(keras.layers.Dense(512, activation='relu'))\n",
    "model_seq.add(keras.layers.Dropout(0.50))\n",
    "model_seq.add(keras.layers.Dense(256, activation='relu'))\n",
    "model_seq.add(keras.layers.Dropout(0.50))\n",
    "model_seq.add(keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "#model_seq.add(base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 150\n",
    "\n",
    "# .Input() instantiates a Keras tensor\n",
    "inputs = keras.Input(shape=(300, 300, 3))\n",
    "# Input layer\n",
    "\n",
    "inputs_resized = tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE)(inputs)\n",
    "# resizing input to match pretrained model\n",
    "\n",
    "x = model_seq(inputs_resized, training=False)\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"global_average_pooling2d_1\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Option 1: Pooling\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert features of shape `base_model.output_shape[1:]` to vectors\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m x_pooling \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGlobalAveragePooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m x_pooling\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\.conda\\envs\\EEE4773\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\EEE4773\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"global_average_pooling2d_1\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 128)"
     ]
    }
   ],
   "source": [
    "# Option 1: Pooling\n",
    "\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x_pooling = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x_pooling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2: Flattening\n",
    "\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x_flatten = keras.layers.Flatten()(x)\n",
    "\n",
    "x_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = keras.layers.Dense(10, activation='softmax')(x_flatten)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "631/631 [==============================] - 432s 678ms/step - loss: 0.5593 - accuracy: 0.8177 - val_loss: 0.2841 - val_accuracy: 0.9118\n",
      "Epoch 2/15\n",
      "631/631 [==============================] - 401s 635ms/step - loss: 0.2630 - accuracy: 0.9097 - val_loss: 0.3734 - val_accuracy: 0.8989\n",
      "Epoch 3/15\n",
      "631/631 [==============================] - 406s 643ms/step - loss: 0.1777 - accuracy: 0.9411 - val_loss: 0.1823 - val_accuracy: 0.9504\n",
      "Epoch 4/15\n",
      "631/631 [==============================] - 397s 629ms/step - loss: 0.1200 - accuracy: 0.9595 - val_loss: 0.2792 - val_accuracy: 0.9405\n",
      "Epoch 5/15\n",
      "631/631 [==============================] - 403s 639ms/step - loss: 0.0945 - accuracy: 0.9682 - val_loss: 0.2525 - val_accuracy: 0.9485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eaced3f880>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_augmented,t_train_augmented, epochs=15, batch_size=32,\n",
    "          validation_data=(X_val_reshaped, t_val),\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)])\n",
    "\n",
    "# Again, in practice, you would run for a lot more epochs. \n",
    "# As well as perform the necessary hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 16s 577ms/step - loss: 0.1197 - accuracy: 0.9674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11972300708293915, 0.9674157500267029]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_reshaped, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 18s 601ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(890,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label predictions\n",
    "y_test = np.argmax(model.predict(X_test_reshaped),axis=1)\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         Nike       0.96      0.98      0.97        90\n",
      "       Adidas       0.99      0.95      0.97        88\n",
      "         Ford       0.99      0.98      0.98        88\n",
      "        Honda       0.98      0.99      0.98        88\n",
      "General_mills       0.98      0.98      0.98        90\n",
      "     Unilever       0.96      1.00      0.98        91\n",
      "    Mcdonalds       0.98      0.94      0.96        88\n",
      "          KFC       0.99      0.92      0.95        88\n",
      "       Gators       0.91      0.97      0.94        88\n",
      "           3M       0.96      0.97      0.96        91\n",
      "\n",
      "     accuracy                           0.97       890\n",
      "    macro avg       0.97      0.97      0.97       890\n",
      " weighted avg       0.97      0.97      0.97       890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(t_test, y_test, target_names=labels_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
